{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5695d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Germany'\n",
    "city = 'Berlin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b795d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from housing_functions import get_driver\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pprint\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "import demjson3\n",
    "import os\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "from housing_functions import random_click, get_driver, search_for_place\n",
    "\n",
    "import json\n",
    "\n",
    "import logging\n",
    "import colorlog\n",
    "\n",
    "import sys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1448b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "255dbd24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98acdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_listings(driver):\n",
    "    pass\n",
    "    \n",
    "def get_logger():\n",
    "    handler = colorlog.StreamHandler()\n",
    "    formatter = colorlog.ColoredFormatter(\n",
    "        \"%(log_color)s%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        log_colors={\n",
    "            \"DEBUG\": \"cyan\",\n",
    "            \"INFO\": \"green\",\n",
    "            \"WARNING\": \"yellow\",\n",
    "            \"ERROR\": \"red\",\n",
    "            \"CRITICAL\": \"bold_red\",\n",
    "        }\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    \n",
    "    logger = colorlog.getLogger(__name__)\n",
    "    logger.addHandler(logging.FileHandler(\"logging.txt\", encoding=\"utf-8\"))\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "    \n",
    "def accept_cookies(driver):\n",
    "    cookies_button = driver.find_element(By.ID,'onetrust-accept-btn-handler')\n",
    "    cookies_button.click()\n",
    "    \n",
    "    \n",
    "def get_container_listings(container):\n",
    "    container.find_elements(By.CLASS_NAME,'css-1efwqj7-cardLink')\n",
    "    return container\n",
    "\n",
    "\n",
    "def create_directory_for_photos():\n",
    "    if not os.path.exists(f'{country}_{city}_house_photos'):\n",
    "        os.mkdir(f'{country}_{city}_house_photos')\n",
    "\n",
    "\n",
    "\n",
    "def get_geo_data(driver):\n",
    "    try:\n",
    "        latitude, longitude, number_of_rooms = None, None, None\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source,'html.parser')\n",
    "        script_elements = soup.find_all('script', type='application/ld+json')\n",
    "        for script in script_elements:\n",
    "            if script.string:\n",
    "                data = json.loads(script.string)\n",
    "                \n",
    "                if data.get('@type') != 'Accommodation':\n",
    "                    continue\n",
    "                geo_data = data.get('geo')\n",
    "                latitude = geo_data.get('latitude')\n",
    "                longitude = geo_data.get('longitude')\n",
    "                number_of_rooms = data.get('numberOfRooms')         \n",
    "    except :\n",
    "        print('Inside the geo_data function, an Exception has occured')    \n",
    "        return None, None, None\n",
    "    \n",
    "    return latitude, longitude, number_of_rooms\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd01c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container(driver):\n",
    "    page_container = driver.find_element(By.CLASS_NAME, 'css-wp5dsn-container')\n",
    "    return page_container\n",
    "\n",
    "def get_container_listings(container):\n",
    "     rows = container.find_elements(By.CLASS_NAME,'css-1efwqj7-cardLink')\n",
    "     return rows\n",
    "\n",
    "\n",
    "def scroll_page(driver):\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_page(driver):\n",
    "    \n",
    "    listings_data_of_this_page = []\n",
    "    \n",
    "    container = get_container(driver)\n",
    "    container_listings = get_container_listings(container)\n",
    "    \n",
    "    \n",
    "    for listing in container_listings:\n",
    "        \n",
    "        listing_data =scrape_listing(listing,driver)\n",
    "        listings_data_of_this_page.append(listing_data)\n",
    "    \n",
    "    \n",
    "    return listings_data_of_this_page\n",
    "    \n",
    "    \n",
    "def get_listing_tags(driver):\n",
    "    try:\n",
    "        tags_container = driver.find_element(By.CLASS_NAME, 'css-q6fy6c-highlightContainer')\n",
    "        if tags_container:\n",
    "            container_elements = tags_container.find_elements(By.CLASS_NAME, 'css-1e5azn1-highlightItem')\n",
    "            tags = []\n",
    "            for tag_element in container_elements:\n",
    "                tag = tag_element.text\n",
    "                tags.append(tag)\n",
    "            return tags\n",
    "    except:\n",
    "        return [None]\n",
    "        \n",
    "        \n",
    "def scrape_listing_photos_and_create_their_file(driver, listing_id:str):\n",
    "    folder = os.path.join(f'{country}_{city}_house_photos', listing_id)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    images_buttons = driver.find_elements(By.CLASS_NAME,'css-13emeri-tile-tileButton')\n",
    "        \n",
    "    # click on more photos so that more photos are loaded\n",
    "    more_photos_button = driver.find_element(By.CLASS_NAME,'css-13emeri-tile-tileButton')\n",
    "    more_photos_button.click()\n",
    "    images = driver.find_elements(By.TAG_NAME, 'img')   \n",
    "    \n",
    "    unique_images = set(images)\n",
    "\n",
    "    \n",
    "    for i, image in enumerate(unique_images):\n",
    "        size = image.size\n",
    "        height = size['height']\n",
    "        if height >= 45:\n",
    "            image_url = image.get_attribute('src') or image.get_attribute('data-src') or image.get_attribute('data-lazy') or image.get_attribute('data-original')\n",
    "            \n",
    "            if image_url.startswith(\"http\"):\n",
    "\n",
    "                response = requests.get(image_url)\n",
    "                image_to_be_written = response.content\n",
    "                \n",
    "                image_bytes = len(image_to_be_written)\n",
    "                if image_bytes > 100 * 1000:\n",
    "                    with open(os.path.join(folder, f'{listing_id}_{i}.jpg'), 'wb') as f1:\n",
    "                        f1.write(image_to_be_written)\n",
    "            else:\n",
    "                print(f'image {i} doesnt start with http')\n",
    "                print(image_url)\n",
    "\n",
    "    \n",
    "    \n",
    "def create_metadata_file_in_the_listings_folder(listing_id,title,price,area,description,full_description,tags,latitude,longitude,number_of_rooms):\n",
    "    try:\n",
    "        print(listing_id.__class__)\n",
    "        if not isinstance(listing_id,str):\n",
    "            logger.error(f'Listing with id; {listing_id} is not of type; str')\n",
    "            raise ValueError\n",
    "        folder = os.path.join(f'{country}_{city}_house_photos', listing_id)    \n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        logger.info(f'Created folder or folder already exists for listing with id; {listing_id}')\n",
    "        file = os.path.join(folder,'.metadata')\n",
    "        with open (file, 'w', encoding='utf-8') as f1:\n",
    "            meta_data = {\n",
    "                'listing_id' : listing_id,\n",
    "                'title' : title,\n",
    "                'price' : price,\n",
    "                'area' : area,\n",
    "                'description' : description,\n",
    "                'full_description' : full_description,\n",
    "                'latitude' : latitude,\n",
    "                'longitude'  : longitude,\n",
    "                'number_of_rooms' : number_of_rooms\n",
    "            }\n",
    "            for i, tag in enumerate(tags):\n",
    "                key = f'tag_{i}'\n",
    "                meta_data[key] = tag\n",
    "                \n",
    "            json_meta_data = json.dumps(meta_data, ensure_ascii= False, indent=4)\n",
    "            f1.write(json_meta_data)\n",
    "            logger.info(f'Wrote meta_data file for listing with id; {listing_id}')\n",
    "    except Exception :\n",
    "        logger.error(f'Encountered error during the writing of the Meta Data file for listing with id; {listing_id}')\n",
    "        driver.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def get_listing_text_attributes(driver):\n",
    "    try:\n",
    "        title = driver.find_element(By.CLASS_NAME,'css-1ql5bbl').text\n",
    "        price = driver.find_element(By.CLASS_NAME, 'css-1bop1zx-pricingContent').text\n",
    "        area = driver.find_element(By.CLASS_NAME, 'css-2ccjfp').text\n",
    "        description = driver.find_element(By.CLASS_NAME, 'css-31lj5q').text\n",
    "        full_description = driver.find_element(By.CLASS_NAME, 'css-1liw7jd-preWrap-breakWord').text\n",
    "\n",
    "        return title, price, area, description, full_description\n",
    "    \n",
    "    except Exception:\n",
    "        return (None,None,None,None,None,)\n",
    "        \n",
    "\n",
    "\n",
    "def get_listing_id(driver):\n",
    "    current_url = driver.current_url\n",
    "    if '/ut' in current_url:\n",
    "        listing_id = current_url.split('/ut')[1].split('/de')[0]\n",
    "    else:    \n",
    "        listing_id = current_url.split('-')[-1]\n",
    "    return listing_id\n",
    "\n",
    "\n",
    "\n",
    "def scrape_listing(listing, driver, original_window):\n",
    "        \n",
    "    try:\n",
    "        listing.click()\n",
    "    except Exception:\n",
    "        logger.error('Didn t manage to sclick on listing.')\n",
    "    \n",
    "    try:\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        listing_id = get_listing_id(driver)\n",
    "        logger.info(f'Acquired listing id {listing_id}')\n",
    "        \n",
    "        title, price, area, description, full_description = get_listing_text_attributes(driver)\n",
    "        logger.info(f'Title : {title}, price : {price}, area : {area}, description : {description}, fulldescription : {full_description}')\n",
    "        \n",
    "        tags = get_listing_tags(driver)\n",
    "        logger.info(f'Tags : {tags}' )\n",
    "        \n",
    "        scrape_listing_photos_and_create_their_file(driver,listing_id)\n",
    "        logger.info('Scraped photos')\n",
    "        \n",
    "        latitude, longitude, number_of_rooms = get_geo_data(driver)\n",
    "        logger.info(f'Latitude {latitude}, longitude : {longitude}, Number of Rooms : {number_of_rooms}')\n",
    "\n",
    "        create_metadata_file_in_the_listings_folder(listing_id,title,price,area,description,full_description,tags,latitude,longitude,number_of_rooms)\n",
    "        logger.info(f'Created metadata file for listing with id ; {listing_id}')\n",
    "    \n",
    "    except Exception:\n",
    "        logger.error('something failed when scraping the data')\n",
    "    finally:\n",
    "        \n",
    "        if driver.current_window_handle != original_window:\n",
    "            driver.close()\n",
    "            driver.switch_to.window(original_window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85857577",
   "metadata": {},
   "source": [
    "<button class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-fullWidth MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-fullWidth css-tkyhxc-button-button\" tabindex=\"0\" type=\"submit\" data-test-locator=\"Search and book\">Search<span class=\"MuiTouchRipple-root css-w0pj6f\"></span></button>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562f5c7",
   "metadata": {},
   "source": [
    "******** PROGRAM STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a2c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "driver = get_driver()\n",
    "create_directory_for_photos()\n",
    "#ipython = get_ipython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tries = 0\n",
    "while True:\n",
    "    try:\n",
    "        tries += 1\n",
    "        if tries == 2:\n",
    "            os.execv(sys.executable, ['python'] + sys.argv)\n",
    "\n",
    "        search_for_place(driver)\n",
    "        accept_cookies(driver)\n",
    "        break\n",
    "\n",
    "    except Exception :\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:19:29,702 [INFO] Trying to get the container element\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:29,751 [INFO] Trying to get the container's listings\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:29,761 [INFO] Iterating over the container's listings\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:29,761 [INFO] Trying to scrape a listing from the container\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:31,835 [INFO] Acquired listing id 2342470\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:31,910 [INFO] Title : Studyo, price : From\n",
      "€850 /month, area : 16 m²+, description : Cleaning in common areas, fulldescription : BOOK NOW & get the December rent for free!*\n",
      "\n",
      "Find your preferred room, book online before 30th September and grab one month rent free\n",
      "in December.\n",
      "Spend your December budget on gifts and fun instead of rent.\n",
      "\n",
      "With us you’ll find more than just an apartment. You’ll find a place that feels like home from day one, where you can focus on your studies, build lasting\n",
      "friendships, and become part of a vibrant international community. Be part of it.\n",
      "Our apartments are fully furnished with modern, comfor...\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:31,919 [INFO] Tags : [None]\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,274 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,349 [INFO] Latitude None, longitude : None, Number of Rooms : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,350 [INFO] Created folder or folder already exists for listing with id; 2342470\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,351 [INFO] Wrote meta_data file for listing with id; 2342470\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,352 [INFO] Created metadata file for listing with id ; 2342470\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:40,421 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:19:41,779 [INFO] Acquired listing id 1148761\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:41,862 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:41,872 [INFO] Tags : [None]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 19 doesnt start with http\n",
      "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:19:57,871 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:57,957 [INFO] Latitude None, longitude : None, Number of Rooms : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:57,958 [INFO] Created folder or folder already exists for listing with id; 1148761\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:57,960 [INFO] Wrote meta_data file for listing with id; 1148761\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:57,961 [INFO] Created metadata file for listing with id ; 1148761\u001b[0m\n",
      "\u001b[32m2025-09-27 17:19:58,020 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:00,370 [INFO] Acquired listing id 551278\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:00,401 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:00,468 [INFO] Tags : ['Entire apartment', 'Property: 27 m²', 'Furnished', 'Space for 2 people', '1 bedroom']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 18 doesnt start with http\n",
      "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:08,337 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:08,425 [INFO] Latitude 52.5097, longitude : 13.42231, Number of Rooms : 1\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:08,427 [INFO] Created folder or folder already exists for listing with id; 551278\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:08,427 [INFO] Wrote meta_data file for listing with id; 551278\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:08,428 [INFO] Created metadata file for listing with id ; 551278\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:08,497 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:09,995 [INFO] Acquired listing id 1030747\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:10,029 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:10,084 [INFO] Tags : ['Entire apartment', 'Property: 23 m²', 'Furnished', 'Space for 1 person', 'Studio', 'Flexible Cancellation']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1 doesnt start with http\n",
      "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:29,686 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:29,754 [INFO] Latitude 52.564, longitude : 13.40742, Number of Rooms : 0\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:29,755 [INFO] Created folder or folder already exists for listing with id; 1030747\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:29,755 [INFO] Wrote meta_data file for listing with id; 1030747\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:29,757 [INFO] Created metadata file for listing with id ; 1030747\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:29,843 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:31,177 [INFO] Acquired listing id 890396\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:31,240 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:31,299 [INFO] Tags : ['Entire apartment', 'Property: 20 m²', 'Furnished', 'Space for 1 person', 'Studio', 'Flexible Cancellation']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 15 doesnt start with http\n",
      "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:43,758 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:43,823 [INFO] Latitude 52.46486, longitude : 13.51172, Number of Rooms : 0\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:43,825 [INFO] Created folder or folder already exists for listing with id; 890396\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:43,826 [INFO] Wrote meta_data file for listing with id; 890396\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:43,827 [INFO] Created metadata file for listing with id ; 890396\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:43,896 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:20:47,746 [INFO] Acquired listing id 1145984\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:47,823 [INFO] Title : Neonwood Adlershof, price : From\n",
      "€765 /month, area : 17 m²+, description : Cleaning in common areas, fulldescription : Life at Berlin Adlershof\n",
      "295 apartments, 295+ students... be one of us & meet extraordinary people. Adlershof is not only a home to renowned non-university research institutions, six institutes of the Humboldt University and around 1,200 companies that are perfect for internships, but also – and this is the best part – our brand new building. Be a part of our community and meet exciting people like you. Our student residence is just a stone’s throw away from the Humboldt University of Berlin – C...\u001b[0m\n",
      "\u001b[32m2025-09-27 17:20:47,832 [INFO] Tags : [None]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 56 doesnt start with http\n",
      "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 17:21:01,194 [INFO] Scraped photos\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:01,344 [INFO] Latitude None, longitude : None, Number of Rooms : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:01,346 [INFO] Created folder or folder already exists for listing with id; 1145984\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:01,348 [INFO] Wrote meta_data file for listing with id; 1145984\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:01,349 [INFO] Created metadata file for listing with id ; 1145984\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:01,419 [INFO] Trying to scrape a listing from the container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025-09-27 17:21:02,467 [ERROR] Didn t manage to sclick on listing.\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:02,474 [INFO] Acquired listing id Germany\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:02,484 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:02,493 [INFO] Tags : [None]\u001b[0m\n",
      "\u001b[31m2025-09-27 17:21:02,511 [ERROR] something failed when scraping the data\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:02,512 [INFO] Trying to scrape a listing from the container\u001b[0m\n",
      "\u001b[31m2025-09-27 17:21:03,544 [ERROR] Didn t manage to sclick on listing.\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:03,551 [INFO] Acquired listing id Germany\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:03,557 [INFO] Title : None, price : None, area : None, description : None, fulldescription : None\u001b[0m\n",
      "\u001b[32m2025-09-27 17:21:03,564 [INFO] Tags : [None]\u001b[0m\n",
      "\u001b[31m2025-09-27 17:21:03,578 [ERROR] something failed when scraping the data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info('Trying to get the container element')\n",
    "    container = driver.find_element(By.CLASS_NAME, 'css-wp5dsn-container')\n",
    "    \n",
    "    scroll_page(driver)\n",
    "    logger.info('Trying to get the container\\'s listings')\n",
    "    container_listings = get_container_listings(container)\n",
    "    \n",
    "    original_window = driver.current_window_handle\n",
    "\n",
    "    logger.info('Iterating over the container\\'s listings')\n",
    "    for  listing in container_listings:\n",
    "        try:\n",
    "            logger.info('Trying to scrape a listing from the container')\n",
    "            listing_data = scrape_listing(listing, driver, original_window)\n",
    "        except ElementClickInterceptedException:\n",
    "            logger.error('Failed to scrape a listing from the container')\n",
    "except Exception :\n",
    "    logger.error('Undefined error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed697776",
   "metadata": {},
   "source": [
    "Next feature testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
